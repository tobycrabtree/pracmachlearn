---
title: "Practical Machine Learning Prediction Assignment"
author: "Tobias Crabtree"
date: "Tuesday, October 21, 2014"
output: html_document
---

The goal of this project is to predict the manner in which 6 participants did barbell lifts correctly and incorrectly (i.e., to predict the "classe" variable in the training set). The weight lifting exercise data for this project come from http://groupware.les.inf.puc-rio.br/har. 

The training and test set data was read into R. The training set consists of 19,622 observations of 160 variables. The testing set consists of 20 observations of 160 variables. An exploratory analysis of the data indicates blank and missing values as well as variables unlikely to be needed for the prediciton, such as a time stamp. Blank and Div 0 values were read as NA, Certain variables not important for prediction were left out of the training set (X, user_name, window and the time stamp variables). Certain variables that had a high amounts of NAs (greater than 80% of valus) were also left out of the training set.

```{r read data} 
require(caret); require(randomForest)

training <- read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", 
                     na.strings=c("NA"," ","","NaN","#DIV/0!")) # read training set

testing <- read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", 
                    na.strings=c("NA"," ","","NaN","DIV/0!")) # read testing set

training <- subset(training, select= -c(X,user_name,raw_timestamp_part_1, raw_timestamp_part_2,
                                        cvtd_timestamp,new_window,num_window)) # remove certain variables

colsRemove <- NULL # identify columns with high amount of NAs
l <- length(names(training))
for (i in 1:l){
  if(sum(is.na(training[i]))/nrow(training) > 0.8)
    colsRemove = c(colsRemove,i)
}
training <- training[,-colsRemove] # remove columns from training

```

Build the classification model using random forest. The training data was split into a training set (70%) and a cross validation set (30%).
```{r training the model} 
library(caret); library(lattice); library(ggplot2); library(e1071)
inTraining <- createDataPartition(training$classe,p=.7, list=FALSE)
trainingTS <- training[inTraining,]
trainingCVS <- training[-inTraining,]

cvCtrl <- trainControl(method="cv", number=10, repeats=5)
modelFit <- train(classe ~., data=trainingTS,method="rf",ntree=100) # classification model
```

Accuracy of the model is summarized below. The estimate of error rate was about 1%. 
```{r model}
modelFit$finalModel
```

Cross-validation was applied. The out of sample error is less than 1%.
```{r cross validation}
predictions <- predict(modelFit,newdata=trainingCVS)
confusionMatrix(trainingCVS$classe,predictions)$table
100*(1-sum(predictions==trainingCVS$classe)/length(predictions))
# calculation out of sample error rate percentage
```

The final prediction from the machine learning algorithm in the 20 test cases is as follows:
```{r prediction}
answers <- predict(modelFit, newdata=testing)
answers
```


Reference: 
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
